#!/usr/bin/env bash

#
# Unauthorized use is prohibited.
#

# MacOS by default has BSD grep, and brew installs GNU grep as ggrep
if command -v ggrep; then
  grep="ggrep"
else
  grep="grep"
fi

get_config() {
  # Read configuration parameter
  $grep -Po "(?<=$1 = \\\").+(?=\\\")" samconfig.toml
}

profile=$(get_config profile)

if [[ $profile = "" ]]; then
  echo "Please set your AWS profile for this deployment in samconfig.toml"
  exit 1
fi

region=$(get_config region)

if [[ $region = "" ]]; then
  echo "Please configure your AWS deployment region by running: aws configure"
  exit 1
fi

nargs=$#

# Use AWS under an explicitly given profile
aws="aws --profile $profile"

check_installed() {
  if ! command -v "$1" &>/dev/null; then
    echo "Install $1: $2"
    exit 1
  fi
}

if [ $nargs -eq 0 ]; then
  echo "Available commands (look inside the script to get a better idea of what they do):"
  echo

  # Finds the commands by inspecting the code

  list=$(grep '"[^"]\+" '$'\051' "$0")

  IFS=$'\n'
  for i in $list; do
    echo -ne "- \e[1;37m$(echo "$i" | cut -d\" -f 2)\e[0m"
    echo -e "\e[33m$(echo "$i" | awk -F '# args:' '{print $2}')\e[0m"
  done

  exit
fi

args () {
  if [[ $((nargs-1)) -lt $1 ]]; then
    echo "This command requires $1 argument(s)"
    exit 1
  fi
}

case $1 in
  "list-functions" )
    $aws lambda list-functions --output json
    ;;

  "list-apis" )
    $aws apigatewayv2 get-apis --output json
    ;;

  "list-api-ids" )
    $0 list-apis | jq -r ".Items[].ApiId"
    ;;

  "list-api-stages" ) # args: [api-id]
    api=${2:-$($0 list-api-ids | head -1)}
    $aws apigatewayv2 get-stages --api-id "$api"
    ;;

  "list-api-stage-names" ) # args: [api-id]
    api=${2:-$($0 list-api-ids | head -1)}
    $0 list-api-stages "$api" | jq -r '.Items[] | .StageName'
    ;;

  "list-api-urls" )
    for api in $($0 list-api-ids); do
      for stage in $($0 list-api-stage-names "$api"); do
        echo "https://$api.execute-api.$region.amazonaws.com/$stage/"
      done
    done
    ;;

  "list-rds-dbs" )
    $aws rds describe-db-instances --output json
    ;;

  "list-rds-db-ids" )
    $0 list-rds-dbs | jq -r ".DBInstances[].DBInstanceIdentifier"
    ;;

  "list-rds-db-endpoints" )
    $0 list-rds-dbs | jq -r ".DBInstances[].Endpoint"
    ;;

  "list-rds-postgres-versions" )
    for ver in $($aws rds describe-db-engine-versions --engine postgres --query "DBEngineVersions[].EngineVersion" --output=text); do
      echo "$ver"
    done
    ;;

  "list-rds-db-instance-options" )
    $aws rds describe-orderable-db-instance-options --engine postgres --engine-version 13.3 --query "*[].{DBInstanceClass:DBInstanceClass,StorageType:StorageType}|[?StorageType=='gp2']|[].{DBInstanceClass:DBInstanceClass}" --output text
    ;;

  "list-stacks" )
    $aws cloudformation describe-stacks --output json | jq -r '.Stacks[].StackName'
    ;;

  "list-stack-params" ) # args: [stack-name]
    $aws cloudformation describe-stacks --stack-name "${2:-$(get_config stack_name)}" | jq -r 'try(.Stacks[0].Parameters[]) | "\(.ParameterKey)=\(.ParameterValue)"'
    ;;

  "list-stack-outputs" ) # args: [stack-name]
    $aws cloudformation describe-stacks --stack-name "${2:-$(get_config stack_name)}" | jq -r 'try(.Stacks[0].Outputs)'
    ;;

  "function-run" ) # args: func-name, [...params]
    args 1

    name=$2
    shift 2

    out=$(mktemp)
    res=$($aws lambda invoke --function-name "$name" --log-type Tail "$out" "$@")

    echo "Execution information:"
    echo
    echo "$res" | jq '.LogResult=(.LogResult | @base64d | gsub("[\t\n]$";"") | gsub("\t";"\n  ") | split("\n"))'
    echo
    echo "Function response: [raw: $out]"
    echo

    status=$(jq -r '.statusCode // empty' < "$out")

    if [ -z "$status" ]; then
      jq . < "$out"
    else
      echo "HTTP code: $status"
      echo
      jq '.body | fromjson' < "$out"
    fi
    ;;

  "function-logs" ) # args: func-name
    args 1

    logstreams=$($aws logs describe-log-streams --log-group-name "/aws/lambda/$2" --query 'logStreams[*].logStreamName' | jq -r '.[-1]')

    if [ -z "$logstreams" ]; then
      echo
      echo "No logs for this function"
    else
      for i in $logstreams; do
        $aws logs get-log-events --log-group-name "/aws/lambda/$2" --log-stream-name "$i" | jq '.events[]'
      done
    fi
    ;;

  "make-cpp-build-environment" ) # args: [<arm|x86>]
    check_installed docker https://docs.docker.com/get-docker/

    set -e

    host_arch=$(uname -m)

    case $2 in
      "" )
        case "$host_arch" in
          aarch64 )
            platform=linux/arm64
            arch=arm
            ;;

          x86_64 )
            platform=linux/amd64
            arch=x86
            ;;

          * )
            echo "Your system architecture ($host_arch) is not supported on AWS Lambda. Choose one of the supported"
            echo "architectures to build on."

            exit 1
            ;;
        esac

        echo "Building for your native CPU architecture: 64-bit $arch"
        echo
        ;;

      arm )
        platform=linux/arm64
        arch=arm

        if [ "$host_arch" != "arm64" ]; then
          echo "Not building for your native architecture (building for 64-bit $arch)"
          echo
        fi
        ;;

      x86 )
        platform=linux/amd64
        arch=x86

        if [ "$host_arch" != "x86_64" ]; then
          echo "Not building for your native architecture (building for 64-bit $arch)"
          echo
        fi
        ;;

      * )
        echo "Architecture must be one of: arm|x86 (assumed 64-bit)"
        echo
        echo "See: https://docs.aws.amazon.com/lambda/latest/dg/foundation-arch.html"

        exit 1
        ;;
    esac

    #
    # If the 'buildx' module is present, use it to enable use of the new BuildKit engine, which is
    # required for cross-architecture builds. Once it becomes the standard build engine for Docker,
    # use of the 'buildx' module will be deprecated and the module might be removed.
    #
    if docker buildx &>/dev/null; then
      buildx=buildx
    fi

    old_image=$(docker images lambda-build-platform -q)

    if [ -n "$old_image" ]; then
      echo "Existing image found: $old_image"
      echo
    fi

    echo "== Building self-contained environment for building and packaging C++ lambdas for deployment"
    echo

    # Build the Docker image that contains the build environment that is ready to build native Lambda functions
    docker $buildx build \
      --network host \
      --progress plain \
      -t lambda-build-platform \
      --platform="$platform" \
      build-environments/cpp

    # Give the image a second tag that labels its platform type
    docker tag lambda-build-platform "lambda-build-platform-$arch"

    if [ -n "$old_image" ]; then
      tags=$(docker image inspect "$old_image" | jq -r '.[].RepoTags[]')

      if [ -z "$tags" ]; then
        echo
        echo "== Deleting the previously existing Docker image"
        echo

        docker rmi "$old_image"
      fi
    fi

    echo
    echo "== Done"
    ;;

  "build-cpp-function" ) # args: func-name [arch] [<debug|release>]
    args 1

    set -e

    # You can pass "-" for 'arch' to use the default container image
    arch=${3:--}

    image=lambda-build-platform

    if [ "$arch" != '-' ]; then
      image="$image-$arch"
    fi

    # Build a debug release by default
    build_type=${4:-debug}

    # Capitalize the build type
    build_type=${build_type^}

    cd "functions/$2"

    echo "Building functions/$2/src/ inside the Docker container"
    echo

    # The docker container finds the source in /mnt/src and produces the package in /mnt/out
    docker run \
      --network host \
      -it --rm \
      -v "$(pwd)":/mnt/src \
      -v /tmp:/mnt/out \
      "$image" \
      /mnt/src/build.sh "$build_type"

    mkdir -p build && cp -v "/tmp/$2.zip" build/

    echo
    echo "The package is ready: functions/$2/build/$2.zip"
    ;;

  "rds-db-action" ) # args: action [instance-id]
    args 1

    #
    # For list of possible actions: `aws rds help`
    #

    if [ -z "$3" ]; then
      ids=$($0 list-rds-db-ids)

      if [[ -z "$ids" ]]; then
        echo "No databases found"
      elif [ "$(echo "$ids" | wc -l)" -gt 1 ]; then
        echo "Found more than one database, please specify an instance id:"
        echo
        echo "$ids"
      else
        id="$ids"
      fi
    else
      id="$3"
    fi

    if [ -n "$id" ]; then
      $aws rds "$2" --db-instance-identifier "$id"
    else
      exit 1
    fi
    ;;

  "rds-db-status" ) # args: [instance-id]
    if [ -n "$2" ]; then
      id="--db-instance-identifier $2"
    fi

    res=$($aws rds describe-db-instances "$id")

    echo "$(echo "$res" | jq -r '.DBInstances[].DBName')": "$(echo "$res" | jq -r '.DBInstances[].DBInstanceStatus')"
    ;;

  "rds-db-hibernate" ) # args: [instance-id]
    set -eo pipefail

    status="$($0 rds-db-action stop-db-instance "$2" | jq -r '.DBInstance.DBInstanceStatus')"

    echo "Status: $status"
    echo
    echo "This may take a while"
    echo
    echo "Check the status with: $0 rds-db-status"
    ;;

  "rds-db-wake" ) # args: [instance-id]
    set -eo pipefail

    status="$($0 rds-db-action start-db-instance "$2" | jq -r '.DBInstance.DBInstanceStatus')"

    echo "Status: $status"
    echo
    echo "This may take a while"
    echo
    echo "Check the status with: $0 rds-db-status"
    ;;

  "rds-db-init" )
    $0 function-run db-init

    echo
    echo !IMPORTANT! - The value of geometry_type_oid changes on every database init
    echo
    echo "Don't forget to run \`sam deploy -g\` and manually specify the DBGeometryTypeOID parameter"
    ;;

  "rds-db-run" ) # args: query, [user]
    args 1

    # Disable filename expansion so that the SQL query will be accepted verbatim
    set -f

    # Escape double quotes in the query, since it is being passed as a JSON value
    a1="\"query\":\"${2//\"/\\\"}\""

    # Include optional user parameter
    [ $# -ge 3 ] && a2=",\"user\": \"$3\""

    json="{$a1$a2}"

    echo "Invoking query function with parameters:"
    echo
    echo "$json" | jq .
    echo

    $0 function-run db-run --payload "$json"
    ;;

  "rds-db-run-file" ) # args: query-file
    args 1

    echo "Invoking query function with parameters:"
    echo
    jq . < "$2"
    echo

    $0 function-run db-run --payload "fileb://$2"
    ;;

  "rds-db-get-security-group" )
    $aws rds describe-db-instances | jq -r ".DBInstances[].VpcSecurityGroups[].VpcSecurityGroupId"
    ;;

  "rds-db-authorize-ingress" )
    sg=$($0 rds-db-get-security-group)
    $aws ec2 authorize-security-group-ingress --group-id "$sg" --protocol tcp --port 5432 --cidr 0.0.0.0/0
    ;;

  "rds-db-deauthorize-ingress" )
    sg=$($0 rds-db-get-security-group)
    $aws ec2 revoke-security-group-ingress --group-id "$sg" --protocol tcp --port 5432 --cidr 0.0.0.0/0
    ;;

  "s3-list-object-tags" ) # args: bucket-name object-key
    $aws s3api get-object-tagging --bucket "$2" --key "$3"
    ;;

  "s3-delete-all" ) # args: bucket-name
    $aws s3 rm "s3://$2" --recursive
    ;;

  "event-log-table-info" )
    $aws dynamodb describe-table --table-name littermap-events
    ;;

  "event-log-table-schema" )
    $0 event-log-table-info | jq .
    ;;

  "event-log" ) # args: [utc-date]
    # Convert today or given UTC date to epoch time
    date=$(date --date="${2:-$(date --utc +"%Y-%m-%d")}" --utc +%s)

    $aws dynamodb query --table-name event-log --key-condition-expression 'date_key = :date' --expression-attribute-values "{\":date\": {\"S\": \"$date\"}}" --scan-index-forward | jq -r '.Items[] | [.timestamp.S, .event.M.message.S] | join(" :: ")'
    ;;

  "stack-cancel-update" ) # args: [stack-name]
    $aws cloudformation cancel-update-stack --stack-name "${2:-$(get_config stack_name)}"
    ;;

  "stack-delete" ) # args: [stack-name]
    sam delete --stack-name "${2:-$(get_config stack_name)}"
    ;;

  "api-export" ) # args: [api-id] [stage]
    out=$(mktemp)
    api=${2:-$($0 list-api-ids | head -1)}
    stage=${3:-$($0 list-api-stage-names "$api" | head -1)}
    $aws apigatewayv2 export-api --api-id "$api" --stage-name "$stage" --specification OAS30 --output-type=YAML "$out"

    cat "$out"
    ;;

  "make-password" )
    $aws secretsmanager get-random-password --output=text
    ;;

  "make-rds-db-password" )
    # As per documented constraints for RDS passwords, replace quotes with |,
    # @ with # and / with \, and then also escape \ as \\
    $0 make-password | tr '/@"'"'" '\\#||' | sed 's/\\/\\\\/g'
    ;;

  "check-service-quotas" )
    service=$2

    if [ -z "$service" ]; then
      # List services with service quotas
      $aws service-quotas list-services | jq -r ".Services[].ServiceCode"
    else
      $aws service-quotas list-service-quotas --service-code "$service"
    fi
    ;;

  "lint" )
    check_installed jshint https://jshint.com/install/

    find {functions,lib}/ -name '*.js' -print0 | xargs -0 jshint
    ;;

  "www-prepare" ) # args: [git-ref]
    check_installed pnpm https://pnpm.io

    ref=${2:-master}

    rm -rf publish/

    git clone git@github.com:earthstewards/littermap.git publish
    cd publish
    echo

    git reset "$ref" --hard
    echo

    pnpm install
    echo

    echo Please configure the front-end in publish/ before publishing
    ;;

  "www-update" ) # args: [git-ref]
    if [ ! -d publish ]; then
      echo First acquire a copy of the front-end repository by running: "$0 www-prepare"
      exit 1
    fi

    ref=${2:-master}

    cd publish
    git reset --hard
    echo
    git pull
    echo
    git reset "$ref" --hard
    echo

    pnpm install
    echo

    echo "Check the configuration and then publish the website"
    ;;

  "www-publish" )
    cd publish

    if ! pnpm run build; then
      echo
      echo "Build failed"

      exit 1
    fi

    echo
    echo -n "Looking for S3 bucket that hosts the website..."

    bucket=$($aws s3 ls | grep website | awk '{ print $3 }')

    if [ "$bucket" = "" ]; then
      echo " not found."
      echo
      echo "Could not publish the website because the hosting S3 bucket was not found"

      exit 1
    else
      echo
      echo
    fi

    echo "Uploading files to S3 bucket: $bucket"
    echo

    $aws s3 sync --acl public-read --cache-control 'max-age=604800' build/ "s3://$bucket" --exclude index.html
    $aws s3 sync --acl public-read --cache-control 'no-cache'       build/ "s3://$bucket"

    echo
    echo "Website files published to: https://$bucket.s3.amazonaws.com"
    ;;

  * )
    echo "Command $1 not available"

    exit 1
    ;;
esac
